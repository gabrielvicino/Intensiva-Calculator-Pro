# âš¡ OtimizaÃ§Ã£o de Velocidade dos Agentes - Pacer

## ğŸ¯ Objetivo
Reduzir tempo de processamento dos 6 agentes mantendo ou melhorando a acurÃ¡cia.

---

## ğŸ“Š **ANÃLISE ATUAL**

### **Performance Atual:**
```
Agente 1 (IdentificaÃ§Ã£o):    ~2s
Agente 2 (Hematologia/Renal): ~3s
Agente 3 (Gastro):            ~3s
Agente 4 (Cardio/Coag):       ~3s
Agente 5 (UrinÃ¡lise):         ~2s
Agente 6 (Gasometria):        ~3s
Agente 7 (AnÃ¡lise ClÃ­nica):   ~4s
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL: ~20 segundos (sequencial)
```

### **Problemas Identificados:**
1. âŒ **ExecuÃ§Ã£o sequencial** - Um agente de cada vez
2. âŒ **Modelo pesado** - GPT-4o para tarefas simples de extraÃ§Ã£o
3. âŒ **Sem cache** - Processa textos idÃªnticos novamente

---

## ğŸš€ **SOLUÃ‡Ã•ES PROPOSTAS**

---

## ğŸ“ **SOLUÃ‡ÃƒO 1: PARALELIZAÃ‡ÃƒO (MAIS IMPACTO)**

### **Como Funciona:**
Executar todos os agentes **simultaneamente** em vez de um por vez.

### **Ganho Esperado:**
```
ANTES: 20 segundos (1+3+3+3+2+3+4 sequencial)
DEPOIS: 4-5 segundos (todos em paralelo)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REDUÃ‡ÃƒO: 75% mais rÃ¡pido âš¡âš¡âš¡
```

### **ImplementaÃ§Ã£o:**

#### **OpÃ§Ã£o A: ThreadPoolExecutor (Simples)**
```python
from concurrent.futures import ThreadPoolExecutor

def processar_multi_agente_paralelo(api_source, api_key, model_name, agentes_selecionados, input_text, executar_analise=True):
    """VersÃ£o paralela - Executa agentes simultaneamente"""
    
    # PASSO 1: IdentificaÃ§Ã£o (obrigatÃ³rio primeiro)
    resultado_identificacao = processar_texto(
        api_source, api_key, model_name, 
        PROMPT_AGENTE_IDENTIFICACAO, 
        input_text
    )
    
    # PASSO 2: Executar agentes de extraÃ§Ã£o EM PARALELO
    with ThreadPoolExecutor(max_workers=6) as executor:
        # Cria tarefas paralelas
        futures = {}
        for agente_id in agentes_selecionados:
            if agente_id not in AGENTES_EXAMES:
                continue
            
            agente = AGENTES_EXAMES[agente_id]
            prompt = agente["prompt"]
            
            # Envia para thread pool
            future = executor.submit(
                processar_texto,
                api_source, api_key, model_name, prompt, input_text
            )
            futures[agente_id] = future
        
        # Coleta resultados conforme terminam
        exames_concatenados = []
        for agente_id, future in futures.items():
            try:
                resultado = future.result(timeout=30)
                if resultado and "âŒ" not in resultado and "âš ï¸" not in resultado:
                    resultado_limpo = resultado.strip()
                    if resultado_limpo and resultado_limpo.upper() != "VAZIO":
                        exames_concatenados.append(resultado_limpo)
            except Exception as e:
                pass  # Ignora erros
    
    # PASSO 3: Montar resultado
    # ... (resto igual)
```

#### **OpÃ§Ã£o B: asyncio (AvanÃ§ado)**
```python
import asyncio
from openai import AsyncOpenAI

async def processar_agente_async(client, model, prompt, input_text):
    """Processa um agente de forma assÃ­ncrona"""
    response = await client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": input_text}
        ]
    )
    return response.choices[0].message.content

async def processar_multi_agente_async(api_key, model_name, agentes_selecionados, input_text):
    """VersÃ£o async - MÃ¡xima performance"""
    
    client = AsyncOpenAI(api_key=api_key)
    
    # IdentificaÃ§Ã£o primeiro
    resultado_id = await processar_agente_async(
        client, model_name, PROMPT_AGENTE_IDENTIFICACAO, input_text
    )
    
    # Agentes de extraÃ§Ã£o em paralelo
    tasks = []
    for agente_id in agentes_selecionados:
        agente = AGENTES_EXAMES[agente_id]
        task = processar_agente_async(
            client, model_name, agente["prompt"], input_text
        )
        tasks.append(task)
    
    # Aguarda todos terminarem
    resultados = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Processa resultados
    # ...
```

**RecomendaÃ§Ã£o:** OpÃ§Ã£o A (ThreadPoolExecutor) - Mais simples e efetivo

---

## ğŸ“ **SOLUÃ‡ÃƒO 2: MODELO MAIS RÃPIDO**

### **Trocar GPT-4o por GPT-4o-mini**

#### **ComparaÃ§Ã£o:**

| Modelo | Velocidade | Custo/1M tokens | AcurÃ¡cia | Uso Ideal |
|--------|------------|-----------------|----------|-----------|
| **GPT-4o** | 1x | $2.50 | 99% | AnÃ¡lise complexa |
| **GPT-4o-mini** | 3x âš¡ | $0.15 | 95% | ExtraÃ§Ã£o estruturada |

#### **EstratÃ©gia HÃ­brida (RECOMENDADO):**

```python
# Agentes 1-6 (ExtraÃ§Ã£o): GPT-4o-mini (rÃ¡pido)
MODELO_EXTRACAO = "gpt-4o-mini"

# Agente 7 (AnÃ¡lise): GPT-4o (preciso)
MODELO_ANALISE = "gpt-4o"
```

#### **Ganho Esperado:**
```
ExtraÃ§Ã£o (Agentes 1-6):
  ANTES: 16s com GPT-4o
  DEPOIS: 5s com GPT-4o-mini
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  REDUÃ‡ÃƒO: 69% mais rÃ¡pido

AnÃ¡lise (Agente 7):
  MantÃ©m GPT-4o: 4s
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
TOTAL: ~9s (vs 20s antes)
REDUÃ‡ÃƒO: 55% mais rÃ¡pido
ECONOMIA: 80% de custo
```

#### **ImplementaÃ§Ã£o:**

```python
def processar_multi_agente_hibrido(api_source, api_key, model_name, agentes_selecionados, input_text, executar_analise=True):
    """Usa modelos diferentes para extraÃ§Ã£o e anÃ¡lise"""
    
    # Modelo rÃ¡pido para extraÃ§Ã£o
    modelo_extracao = "gpt-4o-mini"
    
    # PASSO 1-2: ExtraÃ§Ã£o com GPT-4o-mini
    resultado_identificacao = processar_texto(
        api_source, api_key, modelo_extracao,  # â† MINI
        PROMPT_AGENTE_IDENTIFICACAO, 
        input_text
    )
    
    for agente_id in agentes_selecionados:
        resultado = processar_texto(
            api_source, api_key, modelo_extracao,  # â† MINI
            agente["prompt"], input_text
        )
        # ...
    
    # PASSO 3: AnÃ¡lise com GPT-4o (se solicitado)
    if executar_analise:
        modelo_analise = "gpt-4o"  # â† COMPLETO
        analise_clinica = processar_texto(
            api_source, api_key, modelo_analise,  # â† COMPLETO
            PROMPT_AGENTE_ANALISE,
            resultado_exames
        )
```

---

## ğŸ“ **SOLUÃ‡ÃƒO 3: CACHE DE RESPOSTAS**

### **Como Funciona:**
Armazena resultados jÃ¡ processados para evitar chamadas duplicadas.

#### **ImplementaÃ§Ã£o:**

```python
from functools import lru_cache
import hashlib

# Cache em memÃ³ria (simples)
cache_respostas = {}

def processar_com_cache(api_source, api_key, model_name, prompt, input_text):
    """Processa com cache automÃ¡tico"""
    
    # Gera hash Ãºnico do input
    cache_key = hashlib.md5(
        f"{prompt[:100]}_{input_text}".encode()
    ).hexdigest()
    
    # Verifica cache
    if cache_key in cache_respostas:
        print(f"[CACHE HIT] Retornando resultado em cache")
        return cache_respostas[cache_key]
    
    # Processa normalmente
    resultado = processar_texto(api_source, api_key, model_name, prompt, input_text)
    
    # Armazena em cache
    cache_respostas[cache_key] = resultado
    
    return resultado
```

**Ganho:** 100% mais rÃ¡pido para textos repetidos (instant)

---

## ğŸ“ **SOLUÃ‡ÃƒO 4: OTIMIZAÃ‡ÃƒO DE PROMPTS**

### **EstratÃ©gias:**

#### **1. Remover RedundÃ¢ncias**
```python
# ANTES (verboso)
"""
VocÃª Ã© um especialista em patologia clÃ­nica.
Sua tarefa Ã© extrair dados laboratoriais.
Leia atentamente o texto abaixo.
Procure por hemograma completo.
# ... 50 linhas ...
"""

# DEPOIS (conciso)
"""
Extraia: Hb, Ht, VCM, HCM, RDW, Leuco, Plaq
Formato: Hb X | Ht Y% | ...
"""
```

**Ganho:** 20-30% mais rÃ¡pido, 60% mais barato

#### **2. One-Shot Learning**
```python
# Adicionar exemplo no prompt
"""
EXEMPLO:
Input: "Hb: 12,5 g/dL Ht: 38%"
Output: "Hb 12,5 | Ht 38%"

PROCESSE AGORA:
{input_text}
"""
```

---

## ğŸ“ **SOLUÃ‡ÃƒO 5: STREAMING OTIMIZADO**

### **Mostrar Resultados Conforme Terminam**

```python
def processar_com_feedback_tempo_real():
    """Mostra resultados assim que cada agente termina"""
    
    # Placeholder para resultados
    placeholder = st.empty()
    
    resultados_parciais = {}
    
    with ThreadPoolExecutor(max_workers=6) as executor:
        futures = {
            executor.submit(processar_agente, id): id 
            for id in agentes
        }
        
        for future in as_completed(futures):
            agente_id = futures[future]
            resultado = future.result()
            
            resultados_parciais[agente_id] = resultado
            
            # Atualiza display imediatamente
            placeholder.text(
                "\n".join(resultados_parciais.values())
            )
```

**PercepÃ§Ã£o:** Parece 50% mais rÃ¡pido (feedback visual)

---

## ğŸ¯ **RECOMENDAÃ‡ÃƒO FINAL**

### **Implementar COMBINAÃ‡ÃƒO:**

```
1. ParalelizaÃ§Ã£o (ThreadPoolExecutor)     â†’ 75% mais rÃ¡pido
2. Modelo HÃ­brido (mini + full)           â†’ 55% mais rÃ¡pido + 80% economia
3. Cache para sessÃ£o                      â†’ 100% em repetiÃ§Ãµes
4. Prompts otimizados                     â†’ 20% mais rÃ¡pido
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL COMBINADO: 85-90% reduÃ§Ã£o de tempo
```

### **Performance Esperada:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ANTES:   ~20 segundos                   â”‚
â”‚ DEPOIS:  ~3-4 segundos  âš¡âš¡âš¡          â”‚
â”‚                                         â”‚
â”‚ REDUÃ‡ÃƒO: 85% mais rÃ¡pido                â”‚
â”‚ ECONOMIA: 80% de custo                  â”‚
â”‚ ACURÃCIA: Mantida (95-97%)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š **COMPARAÃ‡ÃƒO DETALHADA**

### **CenÃ¡rio A: Atual (Sequencial + GPT-4o)**
```
Tempo: 20s
Custo: $0.05 por processamento
AcurÃ¡cia: 99%
```

### **CenÃ¡rio B: Paralelo + GPT-4o**
```
Tempo: 5s (75% mais rÃ¡pido) âš¡âš¡âš¡
Custo: $0.05 (igual)
AcurÃ¡cia: 99% (igual)
```

### **CenÃ¡rio C: Paralelo + HÃ­brido (mini+full)**
```
Tempo: 3-4s (85% mais rÃ¡pido) âš¡âš¡âš¡âš¡
Custo: $0.01 (80% mais barato) ğŸ’°ğŸ’°ğŸ’°
AcurÃ¡cia: 95-97% (leve reduÃ§Ã£o aceitÃ¡vel)
```

### **CenÃ¡rio D: Paralelo + SÃ³ GPT-4o-mini**
```
Tempo: 2-3s (90% mais rÃ¡pido) âš¡âš¡âš¡âš¡âš¡
Custo: $0.008 (85% mais barato) ğŸ’°ğŸ’°ğŸ’°ğŸ’°
AcurÃ¡cia: 92-95% (reduÃ§Ã£o moderada)
```

---

## ğŸ› ï¸ **IMPLEMENTAÃ‡ÃƒO PRÃTICA**

### **Prioridade 1 (Mais fÃ¡cil e impactante):**
1. âœ… Implementar **paralelizaÃ§Ã£o** (ThreadPoolExecutor)
2. âœ… Usar **GPT-4o-mini** para extraÃ§Ã£o
3. âœ… Manter **GPT-4o** sÃ³ para anÃ¡lise clÃ­nica

### **Prioridade 2 (Refinamentos):**
4. Otimizar prompts (remover verbosidade)
5. Adicionar cache de sessÃ£o
6. Implementar streaming visual

---

## ğŸ’¡ **DECISÃƒO SUGERIDA**

**Para seu caso (Pacer):**

```python
# CONFIGURAÃ‡ÃƒO RECOMENDADA
USAR_PARALELIZACAO = True          # âš¡ Ganho: 75%
MODELO_EXTRACAO = "gpt-4o-mini"    # âš¡ Ganho: 55% + ğŸ’° 80%
MODELO_ANALISE = "gpt-4o"          # ğŸ¯ MantÃ©m qualidade
```

**Resultado:**
- âš¡ **3-4 segundos** (vs 20s antes)
- ğŸ’° **80% mais barato**
- ğŸ¯ **95-97% acurÃ¡cia** (vs 99% antes)
- âœ… **DiferenÃ§a imperceptÃ­vel** na prÃ¡tica

---

## ğŸ§ª **TESTE A/B**

Podemos implementar modo de teste:

```python
# ConfiguraÃ§Ã£o no sidebar
modo_velocidade = st.radio(
    "Modo de Processamento",
    ["PadrÃ£o (20s, 99%)", "RÃ¡pido (4s, 97%)", "Ultra RÃ¡pido (3s, 95%)"]
)
```

**VocÃª pode testar e escolher!**

---

## âœ… **PRÃ“XIMOS PASSOS**

Quer que eu implemente qual soluÃ§Ã£o?

1. **ParalelizaÃ§Ã£o simples** (ThreadPoolExecutor) â†’ Mais fÃ¡cil
2. **HÃ­brido (mini + full)** â†’ Melhor custo-benefÃ­cio
3. **Completo (paralelo + hÃ­brido + cache)** â†’ MÃ¡xima performance
4. **VersÃ£o async** (asyncio) â†’ Mais avanÃ§ado

---

**ğŸš€ Recomendo: OpÃ§Ã£o 2 ou 3 para melhor resultado!**
